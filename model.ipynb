{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9102483d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv',delimiter=';')\n",
    "\n",
    "df['Target'].value_counts()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee6a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Target'])\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81122254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 ... 0 2 2]\n",
      "X_preprocessed shape: (4424, 52)\n",
      "y_encoded shape: (4424,)\n",
      "Classes: ['Dropout' 'Enrolled' 'Graduate']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Define which columns are numerical and which is the course column\n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "course_column = ['Course']\n",
    "\n",
    "# Remove 'Course' from numerical_columns if it's there\n",
    "if 'Course' in numerical_columns:\n",
    "    numerical_columns.remove('Course')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('course', OneHotEncoder(handle_unknown='ignore'), course_column)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"X_preprocessed shape: {X_preprocessed.shape}\")\n",
    "print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24dabfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3539\n",
      "Test set size: 885\n",
      "Training set class distribution: 2    1767\n",
      "0    1137\n",
      "1     635\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution: 2    442\n",
      "0    284\n",
      "1    159\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data Splitting - using common MLOps best practices\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_preprocessed, \n",
    "    y_encoded, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_encoded  # Maintains class distribution in train/test split\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Training set class distribution: {pd.Series(y_train).value_counts()}\")\n",
    "print(f\"Test set class distribution: {pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "g7150xmd2h4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully!\n",
      "Number of models: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score,recall_score,f1_score\n",
    "import time\n",
    "\n",
    "# Define hyperparameters for each model\n",
    "# You can easily tune these parameters here\n",
    "params = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'max_iter': 1000,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "    'svc': {\n",
    "        'kernel': 'rbf',\n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'max_depth': 10,\n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    'gradient_boosting': {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'n_estimators': 50,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': RANDOM_STATE\n",
    "    },\n",
    "    'knn': {\n",
    "        'n_neighbors': 5,\n",
    "        'n_jobs': -1\n",
    "    },\n",
    "    'gaussian_nb': {}\n",
    "}\n",
    "\n",
    "# Initialize models with specified parameters\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(**params['random_forest']),\n",
    "    'LogisticRegression': LogisticRegression(**params['logistic_regression']),\n",
    "    'SVC': SVC(**params['svc']),\n",
    "    'DecisionTree': DecisionTreeClassifier(**params['decision_tree']),\n",
    "    'GradientBoosting': GradientBoostingClassifier(**params['gradient_boosting']),\n",
    "    'AdaBoost': AdaBoostClassifier(**params['adaboost']),\n",
    "    'KNN': KNeighborsClassifier(**params['knn']),\n",
    "    'GaussianNB': GaussianNB(**params['gaussian_nb'])\n",
    "}\n",
    "\n",
    "print(\"Models initialized successfully!\")\n",
    "print(f\"Number of models: {len(models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "xw254bpwmk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Training RandomForest...\n",
      "  ‚úì Accuracy: 0.7695\n",
      "  ‚úì Precision: 0.7510\n",
      "  ‚úì Recall: 0.7695\n",
      "  ‚úì f1: 0.7455\n",
      "  ‚úì Training time: 0.22 seconds\n",
      "\n",
      "Training LogisticRegression...\n",
      "  ‚úì Accuracy: 0.7718\n",
      "  ‚úì Precision: 0.7542\n",
      "  ‚úì Recall: 0.7718\n",
      "  ‚úì f1: 0.7561\n",
      "  ‚úì Training time: 2.17 seconds\n",
      "\n",
      "Training SVC...\n",
      "  ‚úì Accuracy: 0.7582\n",
      "  ‚úì Precision: 0.7450\n",
      "  ‚úì Recall: 0.7582\n",
      "  ‚úì f1: 0.7449\n",
      "  ‚úì Training time: 0.55 seconds\n",
      "\n",
      "Training DecisionTree...\n",
      "  ‚úì Accuracy: 0.7062\n",
      "  ‚úì Precision: 0.7101\n",
      "  ‚úì Recall: 0.7062\n",
      "  ‚úì f1: 0.7061\n",
      "  ‚úì Training time: 0.03 seconds\n",
      "\n",
      "Training GradientBoosting...\n",
      "  ‚úì Accuracy: 0.7605\n",
      "  ‚úì Precision: 0.7541\n",
      "  ‚úì Recall: 0.7605\n",
      "  ‚úì f1: 0.7552\n",
      "  ‚úì Training time: 5.16 seconds\n",
      "\n",
      "Training AdaBoost...\n",
      "  ‚úì Accuracy: 0.7503\n",
      "  ‚úì Precision: 0.7338\n",
      "  ‚úì Recall: 0.7503\n",
      "  ‚úì f1: 0.7382\n",
      "  ‚úì Training time: 0.23 seconds\n",
      "\n",
      "Training KNN...\n",
      "  ‚úì Accuracy: 0.6678\n",
      "  ‚úì Precision: 0.6474\n",
      "  ‚úì Recall: 0.6678\n",
      "  ‚úì f1: 0.6551\n",
      "  ‚úì Training time: 0.01 seconds\n",
      "\n",
      "Training GaussianNB...\n",
      "  ‚úì Accuracy: 0.6599\n",
      "  ‚úì Precision: 0.6502\n",
      "  ‚úì Recall: 0.6599\n",
      "  ‚úì f1: 0.6540\n",
      "  ‚úì Training time: 0.00 seconds\n",
      "\n",
      "======================================================================\n",
      "All models trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Train all models and store results\n",
    "results = {}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    # Track training time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test,y_pred,average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  ‚úì Precision: {precision:.4f}\")\n",
    "    print(f\"  ‚úì Recall: {recall:.4f}\")\n",
    "    print(f\"  ‚úì f1: {f1:.4f}\")\n",
    "    print(f\"  ‚úì Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "lp5rfqlhpl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created new experiment: Hyperparameter_Tuning\n",
      "‚úì MLflow tracking URI: ./mlruns\n",
      "‚úì Experiment ID: 938850411266971545\n",
      "\n",
      "To view results later, run in terminal:\n",
      "  mlflow ui --backend-store-uri ./mlruns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwong/miniforge3/envs/MLOps/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Install MLflow if not already installed\n",
    "# !pip install mlflow\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import os\n",
    "\n",
    "def setup_mlflow():\n",
    "    \"\"\"Setup MLflow tracking with local file storage\"\"\"\n",
    "    # Use local file-based tracking (no server needed!)\n",
    "    mlflow_tracking_uri = \"./mlruns\"\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    experiment_name = \"Hyperparameter_Tuning\"\n",
    "    \n",
    "    # Create or get experiment\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        print(f\"‚úì Created new experiment: {experiment_name}\")\n",
    "    except:\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\"‚úì Using existing experiment: {experiment_name}\")\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(f\"‚úì MLflow tracking URI: {mlflow_tracking_uri}\")\n",
    "    print(f\"‚úì Experiment ID: {experiment_id}\")\n",
    "    print(f\"\\nTo view results later, run in terminal:\")\n",
    "    print(f\"  mlflow ui --backend-store-uri {mlflow_tracking_uri}\")\n",
    "    \n",
    "    return experiment_name\n",
    "\n",
    "# Setup MLflow\n",
    "experiment_name = setup_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "n06pyk866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models configured for hyperparameter tuning:\n",
      "  ‚Ä¢ RandomForest\n",
      "  ‚Ä¢ GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "# Define models and their hyperparameter search spaces\n",
    "models_to_tune = {\n",
    "    'RandomForest': (RandomForestClassifier(random_state=RANDOM_STATE), {\n",
    "        'n_estimators': [500],\n",
    "        'max_depth': [10, None],\n",
    "        'min_samples_split': [10],\n",
    "        'min_samples_leaf': [1],\n",
    "        'max_features': ['sqrt']\n",
    "    }),\n",
    "    'GradientBoosting': (GradientBoostingClassifier(random_state=RANDOM_STATE), {\n",
    "        'n_estimators': [400],\n",
    "        'learning_rate': [0.1],\n",
    "        'max_depth': [4],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1],\n",
    "        'max_features': ['sqrt']\n",
    "    })\n",
    "}\n",
    "\n",
    "print(\"Models configured for hyperparameter tuning:\")\n",
    "for model_name in models_to_tune.keys():\n",
    "    print(f\"  ‚Ä¢ {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "iqtwowzqm1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Hyperparameter tuning function ready\n"
     ]
    }
   ],
   "source": [
    "def hyperparameter_tuning(model_name, model, param_dist, X_train, y_train, X_val, y_val, n_iter=10, cv=5):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning with RandomizedSearchCV and log results to MLflow\n",
    "    \n",
    "    Parameters:\n",
    "    - model_name: Name of the model\n",
    "    - model: Sklearn model instance\n",
    "    - param_dist: Dictionary of hyperparameter distributions\n",
    "    - X_train, y_train: Training data\n",
    "    - X_val, y_val: Validation data\n",
    "    - n_iter: Number of parameter settings sampled\n",
    "    - cv: Number of cross-validation folds\n",
    "    \n",
    "    Returns:\n",
    "    - best_model: The best trained model\n",
    "    - best_params: The best hyperparameters\n",
    "    - best_score: The best validation score\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_tuning\"):\n",
    "        \n",
    "        # Perform RandomizedSearchCV\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model, \n",
    "            param_distributions=param_dist, \n",
    "            n_iter=n_iter, \n",
    "            cv=cv, \n",
    "            scoring='f1_weighted',  # Good for multi-class imbalanced data\n",
    "            n_jobs=-1, \n",
    "            verbose=2, \n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        start_time = time.time()\n",
    "        random_search.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Get best model and parameters\n",
    "        best_model = random_search.best_estimator_\n",
    "        best_params = random_search.best_params_\n",
    "        best_cv_score = random_search.best_score_\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "        \n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        \n",
    "        # Log parameters to MLflow\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"n_iter\", n_iter)\n",
    "        mlflow.log_param(\"cv_folds\", cv)\n",
    "        \n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"best_cv_f1_score\", best_cv_score)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "        \n",
    "        # Log the model to MLflow\n",
    "        mlflow.sklearn.log_model(best_model, f\"{model_name}_model\")\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\n‚úì Best CV F1 Score: {best_cv_score:.4f}\")\n",
    "        print(f\"‚úì Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"‚úì Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(f\"‚úì Training Time: {training_time:.2f} seconds\")\n",
    "        print(f\"\\nBest Parameters:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "        \n",
    "        return best_model, best_params, val_f1\n",
    "\n",
    "print(\"‚úì Hyperparameter tuning function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "jnqju05t9ag",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING HYPERPARAMETER TUNING WITH MLFLOW TRACKING\n",
      "======================================================================\n",
      "\n",
      "View live results at: http://localhost:5000\n",
      "\n",
      "======================================================================\n",
      "Tuning RandomForest...\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewwong/miniforge3/envs/MLOps/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   5.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 03:57:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/11 03:57:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "/Users/matthewwong/miniforge3/envs/MLOps/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Best CV F1 Score: 0.7580\n",
      "‚úì Validation Accuracy: 0.7774\n",
      "‚úì Validation F1 Score: 0.7596\n",
      "‚úì Training Time: 15.02 seconds\n",
      "\n",
      "Best Parameters:\n",
      "  ‚Ä¢ n_estimators: 500\n",
      "  ‚Ä¢ min_samples_split: 10\n",
      "  ‚Ä¢ min_samples_leaf: 1\n",
      "  ‚Ä¢ max_features: sqrt\n",
      "  ‚Ä¢ max_depth: None\n",
      "\n",
      "======================================================================\n",
      "Tuning GradientBoosting...\n",
      "======================================================================\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.5s\n",
      "[CV] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 03:57:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/11 03:57:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Best CV F1 Score: 0.7720\n",
      "‚úì Validation Accuracy: 0.7627\n",
      "‚úì Validation F1 Score: 0.7567\n",
      "‚úì Training Time: 7.99 seconds\n",
      "\n",
      "Best Parameters:\n",
      "  ‚Ä¢ n_estimators: 400\n",
      "  ‚Ä¢ min_samples_split: 2\n",
      "  ‚Ä¢ min_samples_leaf: 1\n",
      "  ‚Ä¢ max_features: sqrt\n",
      "  ‚Ä¢ max_depth: 4\n",
      "  ‚Ä¢ learning_rate: 0.1\n",
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "Summary of Tuned Models:\n",
      "\n",
      "RandomForest:\n",
      "  Validation F1 Score: 0.7596\n",
      "\n",
      "GradientBoosting:\n",
      "  Validation F1 Score: 0.7567\n",
      "\n",
      "üèÜ Best Overall Model: RandomForest\n",
      "   F1 Score: 0.7596\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter tuning for all models\n",
    "tuned_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING HYPERPARAMETER TUNING WITH MLFLOW TRACKING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nView live results at: http://localhost:5000\")\n",
    "\n",
    "for model_name, (model, param_dist) in models_to_tune.items():\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    best_model, best_params, val_f1 = hyperparameter_tuning(\n",
    "        model_name=model_name,\n",
    "        model=model,\n",
    "        param_dist=param_dist,\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_test,  # Using test set as validation\n",
    "        y_val=y_test,\n",
    "        n_iter=10,  # Number of random combinations to try\n",
    "        cv=5  # 5-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    tuned_results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'params': best_params,\n",
    "        'val_f1_score': val_f1\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nSummary of Tuned Models:\")\n",
    "for model_name, result in tuned_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Validation F1 Score: {result['val_f1_score']:.4f}\")\n",
    "\n",
    "# Find the best overall model\n",
    "best_overall_model = max(tuned_results.items(), key=lambda x: x[1]['val_f1_score'])\n",
    "print(f\"\\nüèÜ Best Overall Model: {best_overall_model[0]}\")\n",
    "print(f\"   F1 Score: {best_overall_model[1]['val_f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fddaf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models...\n",
      "\n",
      "======================================================================\n",
      "‚úì Saved RandomForest to saved_models/run_20251111_035749/RandomForest_acc0.7695.pkl\n",
      "‚úì Saved LogisticRegression to saved_models/run_20251111_035749/LogisticRegression_acc0.7718.pkl\n",
      "‚úì Saved SVC to saved_models/run_20251111_035749/SVC_acc0.7582.pkl\n",
      "‚úì Saved DecisionTree to saved_models/run_20251111_035749/DecisionTree_acc0.7062.pkl\n",
      "‚úì Saved GradientBoosting to saved_models/run_20251111_035749/GradientBoosting_acc0.7605.pkl\n",
      "‚úì Saved AdaBoost to saved_models/run_20251111_035749/AdaBoost_acc0.7503.pkl\n",
      "‚úì Saved KNN to saved_models/run_20251111_035749/KNN_acc0.6678.pkl\n",
      "‚úì Saved GaussianNB to saved_models/run_20251111_035749/GaussianNB_acc0.6599.pkl\n",
      "\n",
      "‚úì Saved preprocessor to saved_models/run_20251111_035749/preprocessor.pkl\n",
      "‚úì Saved label encoder to saved_models/run_20251111_035749/label_encoder.pkl\n",
      "\n",
      "======================================================================\n",
      "All models saved successfully in: saved_models/run_20251111_035749\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a directory to save models\n",
    "models_dir = 'saved_models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Optional: Create a timestamped subdirectory for this training run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "run_dir = os.path.join(models_dir, f'run_{timestamp}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "print(\"Saving models...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save each trained model\n",
    "for model_name, model_data in results.items():\n",
    "    model = model_data['model']\n",
    "    accuracy = model_data['accuracy']\n",
    "    \n",
    "    # Create filename with accuracy for easy reference\n",
    "    model_filename = f\"{model_name}_acc{accuracy:.4f}.pkl\"\n",
    "    model_path = os.path.join(run_dir, model_filename)\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    print(f\"‚úì Saved {model_name} to {model_path}\")\n",
    "\n",
    "# Also save the preprocessor (very important for deployment!)\n",
    "preprocessor_path = os.path.join(run_dir, 'preprocessor.pkl')\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"\\n‚úì Saved preprocessor to {preprocessor_path}\")\n",
    "\n",
    "# Save the label encoder (needed to decode predictions back to class names)\n",
    "label_encoder_path = os.path.join(run_dir, 'label_encoder.pkl')\n",
    "joblib.dump(le, label_encoder_path)\n",
    "print(f\"‚úì Saved label encoder to {label_encoder_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"All models saved successfully in: {run_dir}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
